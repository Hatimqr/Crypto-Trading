{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ad9076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from optStrat import OptStrat\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('/Users/hatim/Desktop/Applied Forecasting/Final Project/Algo Trading/Data.csv', index_col=0, parse_dates=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800feb6e",
   "metadata": {},
   "source": [
    "# Finading the optimal trading strategy in Hindsight\n",
    "- 1 will be buy\n",
    "- -1 will be sell\n",
    "- 0 will be hold\n",
    "\n",
    "The goal is to maximize return while considering trasaction costs. We ignore the volatility adjustment here because it then becomes a non-convex optimization problem that is computationally infeasible. Furthermore, in hindsight the problem is deterministic and the concept of risk is incoherent so we ignore it.\n",
    "\n",
    "\n",
    "## Defining the optimization problem\n",
    "### Starting assumptions\n",
    "we will reduce the labels to the following:\n",
    "- 1 will be in the market (buy all that we can)\n",
    "- 0 will be out of the market (sell all that we can)\n",
    "This can then be trasnformed into our original labels easily.\n",
    "\n",
    "We use dynamic programming for this\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c374d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat=OptStrat(df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c07f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat.df['Signals'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3a3a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Strategy Returns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d627a7",
   "metadata": {},
   "source": [
    "# Learning signals and predicting for the future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee67189",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfa2f1d",
   "metadata": {},
   "source": [
    "## Getting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a7f532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from features import FeatureEngineer\n",
    "\n",
    "\n",
    "engineer = FeatureEngineer(df)\n",
    "engineer.add_all_features()\n",
    "X, y = engineer.get_feature_target_split()\n",
    "X_best, scores, selected_features = engineer.select_best_features(k=25)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d876a77",
   "metadata": {},
   "source": [
    "## Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f590977d",
   "metadata": {},
   "source": [
    "### Check Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8f522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected = X[selected_features]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5557016",
   "metadata": {},
   "source": [
    "### Standardize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4a3abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split(X, y, test_size=0.2):\n",
    "    assert len(X) == len(y)\n",
    "    n = len(X)\n",
    "    test_size = int(n * test_size)\n",
    "    X_train = X[:-test_size]\n",
    "    X_test = X[-test_size:]\n",
    "    y_train = y[:-test_size]\n",
    "    y_test = y[-test_size:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = test_train_split(X_selected, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976d681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29ded87",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a378ea",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6448ca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=500, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test_scaled)\n",
    "y_pred_proba = rf.predict_proba(X_test_scaled)\n",
    "\n",
    "decisions = pd.DataFrame(y_pred_proba, columns=['Sell', 'Hold', 'Buy'], index=X_test.index)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# plot the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Sell', 'Hold', 'Buy'], yticklabels=['Sell', 'Hold', 'Buy'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e13ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "# plot the feature importances\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.barh(X_train.columns, importances)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Random Forest Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49332829",
   "metadata": {},
   "source": [
    "# Simulate Trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0ba9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_data = df[['Close', 'Risk Free Rate']]\n",
    "trade_data = pd.merge(decisions, btc_data, left_index=True, right_index=True, how='left')\n",
    "trade_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2f21c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(trade_data[['Sell', 'Hold', 'Buy']], barmode='group', title='Probabilities of Predictions').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee761d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trader import TradingSimulator\n",
    "\n",
    "simulator = TradingSimulator(trade_data, initial_capital=100, transaction_cost=0.005)\n",
    "simulator.simulate(decision_method='highest_prob')\n",
    "simulator.plot_portfolio_performance()\n",
    "simulator.plot_performance_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f97f47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
